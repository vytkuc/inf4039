{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF4039 Deep Learning Systems / Giliojo mokymo sistemų taikymai\n",
    "**LAB1** \n",
    "**Single layer perceptron**\n",
    "\n",
    "This practical will help you to understand the influence of the basic single-layer perceptron (SLP) parameters on the classification accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import NumPy\n",
    "NumPy library - the most popular choice for linear algebra operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training set of Inputs and corresponding Outputs\n",
    "There are 7 vectors in our Input, and 7 values as ONE vector in our Output.\n",
    "\n",
    "Input of [0, 0, 1, 0] => Output of [0]\n",
    "Input of [1, 1, 1, 0] => Output of [1]\n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_inputs = np.array([[0,0,1,0],\n",
    "                      [1,1,1,0],\n",
    "                      [1,0,1,1],\n",
    "                      [0,1,1,1],\n",
    "                      [0,1,0,1],\n",
    "                      [1,1,1,1],\n",
    "                      [0,0,0,0]])\n",
    "\n",
    "ts_outputs = np.array([[0,1,1,0,0,1,0]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a class to construct Perceptron and Initialize Synapses\n",
    "Random values of Synapse Weights are assigned. NumPy’s random number generator is used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self):\n",
    "        self.synapse_weights = np.random.rand(4,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(self, x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the derivative of Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_deriv(self, x):\n",
    "     return np.exp(-x)/((1 + np.exp(-x))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training function\n",
    "The function train take the parameters:\n",
    "1. **inputs**; our input array defined above\n",
    "2. **real_outputs**; the expected output array, also defined above\n",
    "3. **its**; number of iterations to loop through\n",
    "4. **lr**; learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, inputs, real_outputs, its, lr):\n",
    "    \n",
    "    delta_weights = np.zeros((4,7))\n",
    "    \n",
    "    for iteration in (range(its)):\n",
    "        \n",
    "        # Forward Pass\n",
    "        z = np.dot(inputs, self.syn_weights)\n",
    "        activation = self.sigmoid(z)\n",
    "        \n",
    "        # Backward Pass\n",
    "        for i in range(7):\n",
    "            cost = (activation[i] - real_outputs[i])**2\n",
    "            cost_prime = 2*(activation[i] - real_outputs[i])\n",
    "            for n in range(4):\n",
    "                delta_weights[n][i] = cost_prime * inputs[i][n] * self.sigmoid_deriv(z[i])\n",
    "                \n",
    "    delta_avg = np.array([np.average(delta_weights, axis=1)]).T\n",
    "    self.syn_weights = self.syn_weights - delta_avg*lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back-Propagation\n",
    "This function to allow us to evaluate our model’s predicted outputs given our inputs and the learned synapse weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(self, inputs):\n",
    "     return self.sigmoid(np.dot(inputs, self.syn_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completed code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\n",
      "[[0.0007514023865391206], [0.08286357409809664], [0.08089546192719621], [0.9999944943249781], [0.9999995025579814], [0.9999943482755488], [0.9999417792730834]]\n",
      "[0. 0. 0. 1. 1. 1. 1.]\n",
      "[[14.51378634]\n",
      " [-2.43024214]\n",
      " [-4.76257542]\n",
      " [-2.40406067]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron():\n",
    "    def __init__(self):\n",
    "        self.syn_weights = np.random.rand(4,1)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "    def sigmoid_deriv(self, x):\n",
    "        return np.exp(-x)/((1 + np.exp(-x))**2)\n",
    "\n",
    "    def train(self, inputs, real_outputs, its, lr):\n",
    "\n",
    "        delta_weights = np.zeros((4,7))\n",
    "\n",
    "        for iteration in (range(its)):\n",
    "\n",
    "            # forward pass\n",
    "            z = np.dot(inputs, self.syn_weights)\n",
    "            activation = self.sigmoid(z)\n",
    "\n",
    "            # back pass\n",
    "            for i in range(7):\n",
    "                cost = (activation[i] - real_outputs[i])**2\n",
    "                cost_prime = 2*(activation[i] - real_outputs[i])\n",
    "                for n in range(4):\n",
    "                    delta_weights[n][i] = cost_prime * inputs[i][n] * self.sigmoid_deriv(z[i])\n",
    "\n",
    "            delta_avg = np.array([np.average(delta_weights, axis=1)]).T\n",
    "            self.syn_weights = self.syn_weights - delta_avg*lr\n",
    "\n",
    "    def results(self, inputs):\n",
    "        return self.sigmoid(np.dot(inputs, self.syn_weights))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ts_input = np.array([[0,0,1,0],\n",
    "                         [1,1,1,0],\n",
    "                         [1,0,1,1],\n",
    "                         [0,1,1,1],\n",
    "                         [0,1,0,1],\n",
    "                         [1,1,1,1],\n",
    "                         [0,0,0,0]])\n",
    "\n",
    "    ts_output = np.array([[0,1,1,0,0,1,0]]).T # First Value of Input = output\n",
    "\n",
    "    testing_data = np.array([[0,1,1,0],\n",
    "                             [0,0,0,1],\n",
    "                             [0,1,0,0],\n",
    "                             [1,0,0,1],\n",
    "                             [1,0,0,0],\n",
    "                             [1,1,0,0],\n",
    "                             [1,0,1,0]])\n",
    "\n",
    "    lr = 10 # Learning Rate\n",
    "    steps = 10000\n",
    "    perceptron = Perceptron() # Initialize a perceptron\n",
    "    perceptron.train(ts_input, ts_output, steps, lr) # Train the perceptron\n",
    "\n",
    "    results = []\n",
    "    for x in (range(len(testing_data))):\n",
    "        run = testing_data[x]\n",
    "        trial = perceptron.results(run)\n",
    "        results.append(trial.tolist())\n",
    "    print(\"results\")\n",
    "    print(results)\n",
    "    print(np.ravel(np.rint(results))) # View rounded results\n",
    "    print(perceptron.syn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output values will never reach exactly 0 or 1 since they are passed through a Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0007514023865391206], [0.08286357409809664], [0.08089546192719621], [0.9999944943249781], [0.9999995025579814], [0.9999943482755488], [0.9999417792730834]]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View rounded results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.ravel(np.rint(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing our Synapse Weights serves as a final check to see that our weight is largest for the first Synapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.51378634]\n",
      " [-2.43024214]\n",
      " [-4.76257542]\n",
      " [-2.40406067]]\n"
     ]
    }
   ],
   "source": [
    "print(perceptron.syn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
